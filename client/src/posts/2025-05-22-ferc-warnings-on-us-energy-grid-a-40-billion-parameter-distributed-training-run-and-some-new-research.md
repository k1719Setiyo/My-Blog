---
title: " FERC Warnings on US Energy Grid, a 40 Billion Parameter Distributed
  Training Run, and Some New Research"
date: 2025-05-22T12:05:00.000+04:00
description: FERC, Nous Research, Microsoft & Salesforce, DeepSeek
---
[FERC's 2025 Summer Assessment](https://www.ferc.gov/sites/default/files/2025-05/Summer%20Assessment%202025%205-15-25-001.pdf) signals a demanding period for the U.S. energy grid, with higher temperatures expected to strain already tightening electricity generation margins. This critical situation was underscored by FERC Chairman Mark Christie, who warned, “We are losing dispatchable generation at a pace that is not sustainable and we are not adding sufficient equivalent generation capacity.” Consequently, several regions across the country, including PJM, New England, the Midwest, ERCOT, and the Southwest Power Pool, face an increased likelihood of periods where electricity supply may struggle to meet peak demand. Adding to these pressures,the rapid growth of data centers and crypto-mining facilities presents "unique challenges for demand forecasting and planning" and introduces an "emerging risk" as these large loads are sensitive to grid voltage, potentially causing trips and grid stability problems, even if significant issues are not anticipated this specific summer.

[Nous Research has recently launched](https://nousresearch.com/nous-psyche/?utm_source=alphasignal) an ambitious distributed training run for "Consilience," a 40 billion parameter model, following other recent decentralized AI breakthroughs, like Prime Intellect's 32 billion parameter model. Both companies are champions of open, decentralized AI development with global participation, but utilize distinct technological frameworks. Nous's Psyche system features its DisTrO algorithm for extreme gradient compression and Solana blockchain coordination, specifically focusing on pre-training. Prime Intellect's 'prime' framework, by contrast, employs different communication optimizations and has notably advanced large-scale distributed reinforcement learning. DisTrO's remarkable compression technique reduces data transfer requirements by 1,000-10,000x, making it feasible to train enormous models over standard internet connections without specialized hardware interconnects. The Consilience model, using Multi-head Latent Attention architecture, trains on an impressive 20 trillion token dataset from sources like FineWeb and The Stack V2. This represents the largest publicly disclosed pre-training effort over a distributed internet, potentially democratizing AI development by reducing reliance on large clusters in individual data centers.

[New research by Microsoft and Salesforce](https://arxiv.org/pdf/2505.06120) reveals that Large Language Models (LLMs) significantly underperform in realistic multi-turn conversations where instructions are given piece by piece, showing an average 39% performance drop compared to when they receive a single, complete prompt.This "lost in conversation" phenomenon, observed across 15 top LLMs in over 200,000 simulations using a "sharding" technique to break down instructions, stems not from a major loss of inherent ability (aptitude) but from a dramatic increase in unreliability, making them highly inconsistent. LLMs tend to make premature assumptions, attempt solutions too early, and struggle to correct initial errors, even when new information is provided. This issue affects even the most advanced models, and simple fixes like recapping information or reducing response randomness (temperature) prove largely ineffective at restoring reliability in these conversational settings. The findings highlight a critical need for developers to prioritize improving multi-turn reliability, and for users to be aware of this limitation, ideally consolidating instructions into a single prompt when possible

[A paper published by DeepSeek](https://arxiv.org/pdf/2505.09343), meticulously details the development of their DeepSeek-V3, which was trained on a cluster of 2,048 NVIDIA H800 GPUs, and argues for the critical importance of deep hardware-software co-design for achieving cost-efficient, large-scale AI models. Its significance lies in providing a transparent look into the practical challenges and innovative solutions required to push the boundaries of LLM capabilities, showcasing how their team architected DeepSeek-V3 with specific hardware considerations in mind. Key lessons learned underscore that synergistic innovation is paramount: this includes their practical advancements and applications of memory-efficient Multi-head Latent Attention, compute-optimizing Mixture of Experts, throughput-enhancing FP8 precision training, and a custom Multi-Plane Network Topology to minimize communication overhead. The paper shares these insights, born from navigating real-world hardware bottlenecks, to intentionally spark broader community discussion and offer a foundational blueprint for designing future AI systems where models and next-generation hardware (like improved low-precision units and advanced interconnects) evolve in tandem.
